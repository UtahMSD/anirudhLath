{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HW3 - Scraping and Regression\n",
    "In this assignment we'll analyze some data from the tech news site HackerNews (Links to an external site.). HN has a nice simple HTML table format which makes our scraping less painful than some other websites (cough github cough)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1 - Data Acquisition\n",
    "Check out the robots.txt file for HN to make sure you're allowed to scrape it for stories.\n",
    "\n",
    "Grab the first 5 pages of stories from hackernews. For each story, grab the following data:\n",
    "\n",
    "* Rank (the number of the story on hacker news)\n",
    "* Length of the title\n",
    "* Age, in hours (note, some stories are days or minutes old. You should be able to handle this)\n",
    "* Points (note, some stories don't have scores! Give them 0 points)\n",
    "* Number of comments (again, some stories have no comments. Mark them 0)\n",
    "* A lot of HTML on HN has handy class attributes to help make this task a bit easier. Once you have all your data, create a dataframe to store it, and save a CSV file so you don't have to hit the server repeatedly to reload the data.\n",
    "\n",
    "Most of the table entries are nicely, uniformly formatted, but a few might be missing fields. I'd suggest testing with the common case and fixing edge cases as they come up."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scraping setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# URL for scraping\n",
    "URL = 'https://news.ycombinator.com/news?p='\n",
    "\n",
    "# User Agent Setup\n",
    "headers = {\"User-agent\" : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.5 Safari/605.1.15'}\n",
    "\n",
    "ranks = []\n",
    "title_lengths = []\n",
    "ages_in_hours = []\n",
    "points = []\n",
    "comment_counts = []\n",
    "\n",
    "def scrape(n):\n",
    "    page = requests.get(f'{URL}{n}', headers=headers)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Find ranks\n",
    "    for rank in soup.find_all('span', class_='rank'):\n",
    "        ranks.append(int(rank.get_text().strip().replace('.', '')))\n",
    "\n",
    "    # Title length\n",
    "    for title in soup.find_all('a', class_='titlelink'):\n",
    "        title_lengths.append(len(title.text.strip()))\n",
    "\n",
    "\n",
    "    # Number of comments\n",
    "    for row in soup.find_all('td', class_='subtext'):\n",
    "        # Age\n",
    "        age = row.find(\"span\", class_='age').find('a')\n",
    "        if age is None:\n",
    "            ages_in_hours.append(float(0))\n",
    "        elif 'minute' in age.text:\n",
    "            ages_in_hours.append(float(age.text.strip().replace(\" minute ago\", '').replace('minutes ago', ''))/60)\n",
    "        elif 'day' in age.text:\n",
    "            ages_in_hours.append(float(age.text.strip().replace(\" day ago\", '').replace('days ago', ''))*24)\n",
    "        else:\n",
    "            ages_in_hours.append(float(age.text.strip().replace(\" hour ago\", '').replace('hours ago', '')))\n",
    "\n",
    "        # Points\n",
    "        score = row.find(\"span\", class_='score')\n",
    "        if score is None:\n",
    "            points.append(0)\n",
    "        else:\n",
    "            points.append(int(score.text.strip().replace(' points', '').replace(' point', '')))\n",
    "\n",
    "        # Comments\n",
    "        comment = row.find_all('a')[-1]\n",
    "        if 'comment' in comment.text:\n",
    "            comment_counts.append(int(comment.text.strip().replace(u'\\xa0', u' ').replace(' comments', '').replace('comment', '')))\n",
    "        else:\n",
    "            comment_counts.append(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scrape the website and Verify"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    scrape(i)\n",
    "\n",
    "# print(len(ranks))\n",
    "# print(len(title_lengths))\n",
    "# print(len(ages_in_hours))\n",
    "# print(len(points))\n",
    "# print(len(comment_counts))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating Dataframe and Saving Data as CSV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'rank': ranks, 'title_length': title_lengths, 'age_in_hours' : ages_in_hours, 'points' : points, 'comment_count': comment_counts})\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2 - Regression\n",
    "We're interested in how to get a high-ranking story on Hackernews. Explore several possible least squares regressions to predict a story's rank based on the other variables (or combinations thereof). Include at least 3 different regressions. Compare/contrast them. Which is the most useful.  What are the R^2 scores, p-values for coefficients, and values of the coefficients - and what do these tell us?  Plot at least one of your regressions (see my example below.)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = smf.ols('rank ~ title_length', data=df).fit()\n",
    "print(results.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = smf.ols('rank ~ comment_count', data=df).fit()\n",
    "print(results.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = smf.ols('rank ~ age_in_hours', data=df).fit()\n",
    "print(results.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = smf.ols('rank ~ points', data=df).fit()\n",
    "print(results.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = smf.ols('rank ~ points + comment_count + title_length + age_in_hours', data=df).fit()\n",
    "print(results.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = smf.ols('rank ~ points + age_in_hours', data=df).fit()\n",
    "print(results.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.regplot(x=\"rank\", y=\"points\", data=df).set(title=\"Rank vs. Points\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.regplot(x=\"rank\", y=\"age_in_hours\", data=df).set(title=\"Rank vs. Age in Hours\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analysis\n",
    "Based on my analysis, in terms on a single linear regression of rank against age in hours is the strongest. The other features have an unacceptable amount of p-value to be considered valid for building this model. But when I fit `rank ~ points + age_in_hours`, it seems that the model fits the data much better, and the p-values are also acceptable for both the variable. At the time of current capture, the p-values for points and age in hours are both 0.000. Below I will provide a summary of a few different regressions.\n",
    "<br  />\n",
    "\n",
    "\n",
    "| $Formula$ | $R^2$ | $p-value(s)$ | $co-ef(s)$ |\n",
    "|---|---|---|---|---|\n",
    "| rank ~ points | 0.005 | 0.451 | 0.0189 |\n",
    "| rank ~ age_in_hours | 0.273 | 0.000 | 2.4506 |\n",
    "| rank ~ age_in_hours + points | 0.376 | 0.000, 0.000 | 3.6287, -0.1106|\n",
    "\n",
    "\n",
    "<br  />\n",
    "\n",
    "\n",
    "There seems to be a rough linear relationship between rank against age in hours. But it looks like the most reliable model can be created through a multiple regression of rank against points and age in hours. It makes up about 37.6% of the data based on my recording. But, this model is still inaccurate as it is not completely and is missing many other variables that could be affect this in addition to margin of error due to approximation of values such as age in hours after a day etc. The p-value of points in `rank ~ points` is marginally higher than what is acceptable. It basically shows the accuracy of using that variable being wrong, so basically lower is better, but the according to the standard, anything below a p-value of 0.005 is acceptable to be used in a model.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3 - Classification\n",
    "As smart people, we know that your rank on HN doesn't matter, as long as you're on the front page. Use logistic regression to attempt to classify whether or not an article will be on the front page, given the other (non-rank) variables. Note, you'll need to transform the rank variable into an indicator variable (1 for front page, 0 for not), for example.\n",
    "\n",
    "There are a number of (outdated) ranking formulas for HN publicly available. Take a look at least one of them and perform a regression using the formula to see if least squares regression can compute the coefficients correctly.\n",
    "\n",
    "Include plots showing your regression (for the functions of 1 or 2 variables and your predicted score for an article). What do your regressions tell you about making the front page?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make category column\n",
    "df['is_front_page'] = [1 if x <= 30 else 0 for x in df['rank']]\n",
    "df.head()\n",
    "#df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_reg = smf.logit('is_front_page ~ age_in_hours', df).fit()\n",
    "print(log_reg.summary())\n",
    "sns.regplot(y='is_front_page', x='age_in_hours', logistic=True, data=df, ci=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_reg = smf.logit('is_front_page ~ points', df).fit()\n",
    "print(log_reg.summary())\n",
    "sns.regplot(y='is_front_page', x='points', logistic=True, data=df, ci=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_reg = smf.logit('is_front_page ~ points + age_in_hours', df).fit()\n",
    "print(log_reg.summary())\n",
    "p = log_reg.params\n",
    "predictions = []\n",
    "for index, row in df.iterrows() :\n",
    "    predictions.append(p.Intercept + p.points * row.points + p.age_in_hours * row.age_in_hours)\n",
    "\n",
    "df[\"my_predictions\"] = predictions\n",
    "sns.regplot(y='is_front_page', x='my_predictions', data=df, logistic=True)\n",
    "\n",
    "ax = df.plot(x='rank', y='my_predictions', kind='scatter', c='is_front_page', colormap='viridis', figsize=[10,10])\n",
    "print(df.head())\n",
    "\n",
    "x=df['rank']\n",
    "ax.plot(x, [p.Intercept + p.points + p.age_in_hours for x in range(1,121)])\n",
    "ax.set_xlim([1, 121])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Formula found online >> (points - 1) / (time + 2) ** 1.8\n",
    "predictions = []\n",
    "for index, row in df.iterrows():\n",
    "    predictions.append((row.points - 1) / (row.age_in_hours + 2)**1.8)\n",
    "\n",
    "df[\"other_predictions\"] = predictions\n",
    "sns.regplot(y='is_front_page', x='other_predictions', data=df, logistic=True)\n",
    "\n",
    "ax = df.plot(x='rank', y='other_predictions', kind='scatter', c='is_front_page', colormap='viridis', figsize=[10, 10])\n",
    "print(df.head())\n",
    "\n",
    "x = df['rank']\n",
    "ax.plot(x, [1.5 for x in range(1,121)])\n",
    "ax.set_xlim([1, 121])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}