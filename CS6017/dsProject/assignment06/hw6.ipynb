{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HW6 - Character Classification\n",
    "Anirudh Lath | CS6017 | July 24, 2022\n",
    "In this assignment we'll tackle a slightly more complicated image classification problem than MNIST digit classification. We're going to classify characters that contain (gasp!) letters!\n",
    "\n",
    "The dataset we'll play with is from University of California, Irvine (UCI) and contains a bunch of images of letters of various fonts. Some printed + scanned, some the values screen-capped from a computer. The images are 20x20 pixels, grayscale."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Data Acquisition + Cleanup\n",
    "Import the data for Arial font"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3080\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\memory.py:391: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fonts/ARIAL.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 29>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllocated:\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mround\u001B[39m(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mmemory_allocated(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m1024\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m1\u001B[39m), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGB\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCached:   \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mround\u001B[39m(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mmemory_cached(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m1024\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m1\u001B[39m), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGB\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 29\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfonts/ARIAL.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m df\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    666\u001B[0m     dialect,\n\u001B[0;32m    667\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    677\u001B[0m )\n\u001B[0;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    930\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1213\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1214\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[0;32m   1215\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[0;32m   1216\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[1;32m-> 1217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[0;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1226\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1227\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1228\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    784\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    785\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    786\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    788\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    795\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'fonts/ARIAL.csv'"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5),(0.5))]) #convert from images to tensors\n",
    "mnist_test  = torchvision.datasets.MNIST( \"./mnist\", train=False, download=True, transform=transform )\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "\n",
    "df = pd.read_csv('fonts/ARIAL.csv')\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop all columns except m_label and the pixel values which are scattered across 400 columns labeled rxcy (where x and y are the row and column numbers that range from 0 to 19)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     m_label  r0c0  r0c1  r0c2  r0c3  r0c4  r0c5  r0c6  r0c7  r0c8  ...  \\\n0      61442     1     1     1     1     1     1     1     1     1  ...   \n1      61441     1     1     1     1     1     1     1     1     1  ...   \n2      61440   255   123   123   123   123   123   123   123   123  ...   \n3       9674     1     1     1     1     1     1     1     1    64  ...   \n4       8805    46   176   238   203    80    80    53     1     1  ...   \n..       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n975       37     1     1     1     1     1     1     1    39   125  ...   \n976       36     1     1     1     1     1     1     1     1     1  ...   \n977       35     1     1     1     1     1     1     1     1     1  ...   \n978       34     1     1     1     1     1     1   192   255   255  ...   \n979       33     1     1     1     1     1     1     1     1     1  ...   \n\n     r19c10  r19c11  r19c12  r19c13  r19c14  r19c15  r19c16  r19c17  r19c18  \\\n0         1       1       1       1       1       1       1       1       1   \n1         1       1       1       1       1       1       1       1       1   \n2       123     123     123     123     123     123     123     123     123   \n3       255     192     118      10       1       1       1       1       1   \n4        80      80      80     197      93     158     255     255     255   \n..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n975     222     229     125      42       1       1       1       1       1   \n976       1       1       1       1       1       1       1       1       1   \n977       1       1       1       1       1       1       1       1       1   \n978     255      64       1       1       1       1       1       1       1   \n979       1       1       1       1       1       1       1       1       1   \n\n     r19c19  \n0         1  \n1         1  \n2       255  \n3         1  \n4        67  \n..      ...  \n975       1  \n976       1  \n977       1  \n978       1  \n979       1  \n\n[980 rows x 401 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>m_label</th>\n      <th>r0c0</th>\n      <th>r0c1</th>\n      <th>r0c2</th>\n      <th>r0c3</th>\n      <th>r0c4</th>\n      <th>r0c5</th>\n      <th>r0c6</th>\n      <th>r0c7</th>\n      <th>r0c8</th>\n      <th>...</th>\n      <th>r19c10</th>\n      <th>r19c11</th>\n      <th>r19c12</th>\n      <th>r19c13</th>\n      <th>r19c14</th>\n      <th>r19c15</th>\n      <th>r19c16</th>\n      <th>r19c17</th>\n      <th>r19c18</th>\n      <th>r19c19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>61442</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>61441</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>61440</td>\n      <td>255</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>...</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>255</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9674</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>64</td>\n      <td>...</td>\n      <td>255</td>\n      <td>192</td>\n      <td>118</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8805</td>\n      <td>46</td>\n      <td>176</td>\n      <td>238</td>\n      <td>203</td>\n      <td>80</td>\n      <td>80</td>\n      <td>53</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>80</td>\n      <td>80</td>\n      <td>80</td>\n      <td>197</td>\n      <td>93</td>\n      <td>158</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>975</th>\n      <td>37</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>39</td>\n      <td>125</td>\n      <td>...</td>\n      <td>222</td>\n      <td>229</td>\n      <td>125</td>\n      <td>42</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>976</th>\n      <td>36</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>977</th>\n      <td>35</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>978</th>\n      <td>34</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>192</td>\n      <td>255</td>\n      <td>255</td>\n      <td>...</td>\n      <td>255</td>\n      <td>64</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>979</th>\n      <td>33</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>980 rows Ã— 401 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['font', 'fontVariant', 'strength', 'italic', 'orientation', 'm_top', 'm_left', 'originalH', 'originalW', 'h', 'w'], inplace=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, write a function that takes in one of these types of dataframe and returns 2 numpy arrays: Xs which is a #samples x 20 x 20 array containing the pixel values, and Ys which is a #samples x 1 array containing the ascii vales for each character. You should normalize the Xs array so the values go from 0-1 (most likely this requires dividing by 255)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([244, 243, 242, 241, 240, 239, 238, 237, 236, 235, 234, 233, 232,\n       231, 230, 229, 228, 227, 226, 225, 224, 223, 222, 221, 220, 219,\n       218, 217, 216, 215, 214, 213, 212, 211, 210, 209, 208, 207, 206,\n       205, 204, 203, 202, 201, 200, 199, 198, 197, 196, 195, 194, 193,\n       192, 191, 190, 189, 188, 187, 186, 185, 184, 183, 182, 181, 180,\n       179, 178, 177, 176, 175, 174, 173, 172, 171, 170, 169, 168, 167,\n       166, 165, 164, 163, 162, 161, 160, 159, 158, 157, 156, 155, 154,\n       153, 152, 151, 150, 149, 148, 147, 146, 145, 144, 143, 142, 141,\n       140, 139, 138, 137, 136, 135, 134, 133, 132, 131, 130, 129, 128,\n       127, 126, 125, 124, 123, 122, 121, 120, 119, 118, 117, 116, 115,\n       114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102,\n       101, 100,  99,  98,  97,  96,  95,  94,  93,  92,  91,  90,  89,\n        88,  87,  86,  85,  84,  83,  82,  81,  80,  79,  78,  77,  76,\n        75,  74,  73,  72,  71,  70,  69,  68,  67,  66,  65,  64,  63,\n        62,  61,  60,  59,  58,  57,  56,  55,  54,  53,  52,  51,  50,\n        49,  48,  47,  46,  45,  44,  43,  42,  41,  40,  39,  38,  37,\n        36,  35,  34,  33,  32,  31,  30,  29,  28,  27,  26,  25,  24,\n        23,  22,  21,  20,  19,  18,  17,  16,  15,  14,  13,  12,  11,\n        10,   9,   8,   7,   6,   5,   4,   3,   2,   1,   0, 244, 243,\n       242, 241, 240, 239, 238, 237, 236, 235, 234, 233, 232, 231, 230,\n       229, 228, 227, 226, 225, 224, 223, 222, 221, 220, 219, 218, 217,\n       216, 215, 214, 213, 212, 211, 210, 209, 208, 207, 206, 205, 204,\n       203, 202, 201, 200, 199, 198, 197, 196, 195, 194, 193, 192, 191,\n       190, 189, 188, 187, 186, 185, 184, 183, 182, 181, 180, 179, 178,\n       177, 176, 175, 174, 173, 172, 171, 170, 169, 168, 167, 166, 165,\n       164, 163, 162, 161, 160, 159, 158, 157, 156, 155, 154, 153, 152,\n       151, 150, 149, 148, 147, 146, 145, 144, 143, 142, 141, 140, 139,\n       138, 137, 136, 135, 134, 133, 132, 131, 130, 129, 128, 127, 126,\n       125, 124, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113,\n       112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100,\n        99,  98,  97,  96,  95,  94,  93,  92,  91,  90,  89,  88,  87,\n        86,  85,  84,  83,  82,  81,  80,  79,  78,  77,  76,  75,  74,\n        73,  72,  71,  70,  69,  68,  67,  66,  65,  64,  63,  62,  61,\n        60,  59,  58,  57,  56,  55,  54,  53,  52,  51,  50,  49,  48,\n        47,  46,  45,  44,  43,  42,  41,  40,  39,  38,  37,  36,  35,\n        34,  33,  32,  31,  30,  29,  28,  27,  26,  25,  24,  23,  22,\n        21,  20,  19,  18,  17,  16,  15,  14,  13,  12,  11,  10,   9,\n         8,   7,   6,   5,   4,   3,   2,   1,   0, 244, 243, 242, 241,\n       240, 239, 238, 237, 236, 235, 234, 233, 232, 231, 230, 229, 228,\n       227, 226, 225, 224, 223, 222, 221, 220, 219, 218, 217, 216, 215,\n       214, 213, 212, 211, 210, 209, 208, 207, 206, 205, 204, 203, 202,\n       201, 200, 199, 198, 197, 196, 195, 194, 193, 192, 191, 190, 189,\n       188, 187, 186, 185, 184, 183, 182, 181, 180, 179, 178, 177, 176,\n       175, 174, 173, 172, 171, 170, 169, 168, 167, 166, 165, 164, 163,\n       162, 161, 160, 159, 158, 157, 156, 155, 154, 153, 152, 151, 150,\n       149, 148, 147, 146, 145, 144, 143, 142, 141, 140, 139, 138, 137,\n       136, 135, 134, 133, 132, 131, 130, 129, 128, 127, 126, 125, 124,\n       123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111,\n       110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100,  99,  98,\n        97,  96,  95,  94,  93,  92,  91,  90,  89,  88,  87,  86,  85,\n        84,  83,  82,  81,  80,  79,  78,  77,  76,  75,  74,  73,  72,\n        71,  70,  69,  68,  67,  66,  65,  64,  63,  62,  61,  60,  59,\n        58,  57,  56,  55,  54,  53,  52,  51,  50,  49,  48,  47,  46,\n        45,  44,  43,  42,  41,  40,  39,  38,  37,  36,  35,  34,  33,\n        32,  31,  30,  29,  28,  27,  26,  25,  24,  23,  22,  21,  20,\n        19,  18,  17,  16,  15,  14,  13,  12,  11,  10,   9,   8,   7,\n         6,   5,   4,   3,   2,   1,   0, 244, 243, 242, 241, 240, 239,\n       238, 237, 236, 235, 234, 233, 232, 231, 230, 229, 228, 227, 226,\n       225, 224, 223, 222, 221, 220, 219, 218, 217, 216, 215, 214, 213,\n       212, 211, 210, 209, 208, 207, 206, 205, 204, 203, 202, 201, 200,\n       199, 198, 197, 196, 195, 194, 193, 192, 191, 190, 189, 188, 187,\n       186, 185, 184, 183, 182, 181, 180, 179, 178, 177, 176, 175, 174,\n       173, 172, 171, 170, 169, 168, 167, 166, 165, 164, 163, 162, 161,\n       160, 159, 158, 157, 156, 155, 154, 153, 152, 151, 150, 149, 148,\n       147, 146, 145, 144, 143, 142, 141, 140, 139, 138, 137, 136, 135,\n       134, 133, 132, 131, 130, 129, 128, 127, 126, 125, 124, 123, 122,\n       121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109,\n       108, 107, 106, 105, 104, 103, 102, 101, 100,  99,  98,  97,  96,\n        95,  94,  93,  92,  91,  90,  89,  88,  87,  86,  85,  84,  83,\n        82,  81,  80,  79,  78,  77,  76,  75,  74,  73,  72,  71,  70,\n        69,  68,  67,  66,  65,  64,  63,  62,  61,  60,  59,  58,  57,\n        56,  55,  54,  53,  52,  51,  50,  49,  48,  47,  46,  45,  44,\n        43,  42,  41,  40,  39,  38,  37,  36,  35,  34,  33,  32,  31,\n        30,  29,  28,  27,  26,  25,  24,  23,  22,  21,  20,  19,  18,\n        17,  16,  15,  14,  13,  12,  11,  10,   9,   8,   7,   6,   5,\n         4,   3,   2,   1,   0], dtype=int64)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_data(df):\n",
    "    #Xs which is a #samples x 20 x 20 array containing the pixel values\n",
    "    X = df.drop(columns='m_label').to_numpy(dtype=np.float64)\n",
    "    X = np.array([x.reshape(20, 20) for x in X], dtype=np.float64) / 255\n",
    "    X = np.reshape(X, (-1, 1, 20, 20))\n",
    "\n",
    "    #Ys\n",
    "    Y_data = df[\"m_label\"].to_numpy()\n",
    "    keys, Y = np.unique(Y_data, return_inverse=True)\n",
    "    # Y = np.array(Y_data)\n",
    "\n",
    "    return X, Y , keys\n",
    "\n",
    "X, Y, keys = extract_data(df)\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Build a PyTorch Network\n",
    "We're going to use the PyTorch library, like we've seen in class, to build/train our network. Check out the notebooks we've made in class or the official documentation/tutorials.\n",
    "\n",
    "To start with, we're going to use a model very similar to the MNIST CNN we used in class. It will consist of:\n",
    "\n",
    "* a Convolution2D layer with ReLU activations\n",
    "* a max pooling layer\n",
    "* another convolution layer\n",
    "* another max pooling layer\n",
    "* a dense layer with relu activation\n",
    "* a dense layer\n",
    "\n",
    "Compile and train your network like we did in class. You'll probably have to use the np.reshape() function on your data to make PyTorch happy. I reshaped my X values like np.reshape(Xs, (-1, 1, 20, 20)) to get them in the right format.\n",
    "\n",
    "For training, you'll want to check out torch.utils.data.DataLoader which can take a TensorDataset so you can iterate over batches like we did in class for the MNIST data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class network1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(network1, self).__init__()\n",
    "\n",
    "        self.convolution1 = nn.Conv2d(1, 8, 3)\n",
    "        self.pooling1 = nn.MaxPool2d(2, 2)\n",
    "        self.dense1 = nn.Linear(576, 4000)\n",
    "\n",
    "        self.convolution2 = nn.Conv2d(8, 64, 3)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 2)\n",
    "        self.dense2 = nn.Linear(4000, 3097)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pooling1(F.relu(self.convolution1(x)))\n",
    "        x = self.pooling2(F.relu(self.convolution2(x)))\n",
    "\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        # Exclude Batch Dimension\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "network1 = network1()\n",
    "\n",
    "def train( model, epochs, data, labels ):\n",
    "    # model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # use the optimiser to find weights\n",
    "    optimizer = optim.Adam( model.parameters(), lr= 1e-4 )\n",
    "\n",
    "    model.float()\n",
    "\n",
    "    for epoch in range( epochs ):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(data.float()) # Predict outputs\n",
    "        loss = criterion(outputs, labels) # Check the predictions accuracy\n",
    "\n",
    "        loss.backward() # Calculate new weights\n",
    "        optimizer.step() # Change weights and try again\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('Model has been trained!')\n",
    "\n",
    "def evaluate( model, data, labels ):\n",
    "    #load some test data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad(): # Don't calculate gradients as it's not necessary here.\n",
    "\n",
    "        outputs = model(data.float())\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print( 'Accuracy of the network on Arial Font: %d %%' % (100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(244)\n",
      "Training the model, please wait...\n",
      "Model has been trained!\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "data = torch.from_numpy(X)\n",
    "labels = torch.from_numpy(Y)\n",
    "# data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "print(min(labels))\n",
    "print(max(labels))\n",
    "\n",
    "print(\"Training the model, please wait...\")\n",
    "train(network1, 15, data, labels)\n",
    "print(\"Training complete.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}