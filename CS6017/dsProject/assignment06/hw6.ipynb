{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HW6 - Character Classification\n",
    "Anirudh Lath | CS6017 | July 24, 2022\n",
    "In this assignment we'll tackle a slightly more complicated image classification problem than MNIST digit classification. We're going to classify characters that contain (gasp!) letters!\n",
    "\n",
    "The dataset we'll play with is from University of California, Irvine (UCI) and contains a bunch of images of letters of various fonts. Some printed + scanned, some the values screen-capped from a computer. The images are 20x20 pixels, grayscale."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3080\n",
      "Memory Usage:\n",
      "Allocated: 0.3 GB\n",
      "Cached:    1.7 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\memory.py:391: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prepare the notebook\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5),(0.5))]) #convert from images to tensors\n",
    "mnist_test  = torchvision.datasets.MNIST( \"./mnist\", train=False, download=True, transform=transform )\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "EPOCHS = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Data Acquisition + Cleanup\n",
    "Import the data for Arial font"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "    font fontVariant  m_label  strength  italic  orientation  m_top  m_left  \\\n0  ARIAL     scanned       48       0.4       0          0.0      0       0   \n1  ARIAL     scanned       50       0.4       0          0.0      0       0   \n2  ARIAL     scanned       83       0.4       0          0.0      0       0   \n3  ARIAL     scanned       48       0.4       0          0.0      0       0   \n4  ARIAL     scanned       54       0.4       0          0.0      0       0   \n\n   originalH  originalW  ...  r19c10  r19c11  r19c12  r19c13  r19c14  r19c15  \\\n0         15         25  ...     255     255     255     154       1       1   \n1         18         11  ...     213     225     229     239     240     240   \n2         13         10  ...     255     255     255     255     255     255   \n3         15         18  ...       1       1       1       1       1       1   \n4         14         30  ...     255     255     255     255       1       1   \n\n   r19c16  r19c17  r19c18  r19c19  \n0       1       1       1       1  \n1     221     209     116      95  \n2       1       1       1       1  \n3       1       1       1       1  \n4       1       1       1       1  \n\n[5 rows x 412 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>font</th>\n      <th>fontVariant</th>\n      <th>m_label</th>\n      <th>strength</th>\n      <th>italic</th>\n      <th>orientation</th>\n      <th>m_top</th>\n      <th>m_left</th>\n      <th>originalH</th>\n      <th>originalW</th>\n      <th>...</th>\n      <th>r19c10</th>\n      <th>r19c11</th>\n      <th>r19c12</th>\n      <th>r19c13</th>\n      <th>r19c14</th>\n      <th>r19c15</th>\n      <th>r19c16</th>\n      <th>r19c17</th>\n      <th>r19c18</th>\n      <th>r19c19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ARIAL</td>\n      <td>scanned</td>\n      <td>48</td>\n      <td>0.4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15</td>\n      <td>25</td>\n      <td>...</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>154</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ARIAL</td>\n      <td>scanned</td>\n      <td>50</td>\n      <td>0.4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>11</td>\n      <td>...</td>\n      <td>213</td>\n      <td>225</td>\n      <td>229</td>\n      <td>239</td>\n      <td>240</td>\n      <td>240</td>\n      <td>221</td>\n      <td>209</td>\n      <td>116</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ARIAL</td>\n      <td>scanned</td>\n      <td>83</td>\n      <td>0.4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>10</td>\n      <td>...</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ARIAL</td>\n      <td>scanned</td>\n      <td>48</td>\n      <td>0.4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15</td>\n      <td>18</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ARIAL</td>\n      <td>scanned</td>\n      <td>54</td>\n      <td>0.4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>30</td>\n      <td>...</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 412 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fonts/ARIAL.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop all columns except m_label and the pixel values which are scattered across 400 columns labeled rxcy (where x and y are the row and column numbers that range from 0 to 19)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "       m_label  r0c0  r0c1  r0c2  r0c3  r0c4  r0c5  r0c6  r0c7  r0c8  ...  \\\n0           48     1     1     1     1     1     1   154   255   255  ...   \n1           50     4     7    22    49    97   120   139   156   162  ...   \n2           83     1     1     1     1   255   255   255   255   255  ...   \n3           48     1     1     1     1     1   114   255   255   255  ...   \n4           54     1     1     1     1     1     1     1     1   255  ...   \n...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n26232       37     1     4    83   208   255   255   161    16     1  ...   \n26233       36     1     1     1     1     1     1     1     1     1  ...   \n26234       35     1     1     1     1     1     1    77   253   255  ...   \n26235       34    43   255   255   255   255   255   255   255   255  ...   \n26236       33     1     1     1     1     1     1     1     1     1  ...   \n\n       r19c10  r19c11  r19c12  r19c13  r19c14  r19c15  r19c16  r19c17  r19c18  \\\n0         255     255     255     154       1       1       1       1       1   \n1         213     225     229     239     240     240     221     209     116   \n2         255     255     255     255     255     255       1       1       1   \n3           1       1       1       1       1       1       1       1       1   \n4         255     255     255     255       1       1       1       1       1   \n...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n26232       1       1      16     161     255     255     208      83       4   \n26233       1       1       1       1       1       1       1       1       1   \n26234     255     255     253      77       1       1       1       1       1   \n26235      43     255     255     255     255     213       1       1       1   \n26236      23       1       1       1       1       1       1       1       1   \n\n       r19c19  \n0           1  \n1          95  \n2           1  \n3           1  \n4           1  \n...       ...  \n26232       1  \n26233       1  \n26234       1  \n26235       1  \n26236       1  \n\n[26237 rows x 401 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>m_label</th>\n      <th>r0c0</th>\n      <th>r0c1</th>\n      <th>r0c2</th>\n      <th>r0c3</th>\n      <th>r0c4</th>\n      <th>r0c5</th>\n      <th>r0c6</th>\n      <th>r0c7</th>\n      <th>r0c8</th>\n      <th>...</th>\n      <th>r19c10</th>\n      <th>r19c11</th>\n      <th>r19c12</th>\n      <th>r19c13</th>\n      <th>r19c14</th>\n      <th>r19c15</th>\n      <th>r19c16</th>\n      <th>r19c17</th>\n      <th>r19c18</th>\n      <th>r19c19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>48</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>154</td>\n      <td>255</td>\n      <td>255</td>\n      <td>...</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>154</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>4</td>\n      <td>7</td>\n      <td>22</td>\n      <td>49</td>\n      <td>97</td>\n      <td>120</td>\n      <td>139</td>\n      <td>156</td>\n      <td>162</td>\n      <td>...</td>\n      <td>213</td>\n      <td>225</td>\n      <td>229</td>\n      <td>239</td>\n      <td>240</td>\n      <td>240</td>\n      <td>221</td>\n      <td>209</td>\n      <td>116</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>83</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>...</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>114</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>255</td>\n      <td>...</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26232</th>\n      <td>37</td>\n      <td>1</td>\n      <td>4</td>\n      <td>83</td>\n      <td>208</td>\n      <td>255</td>\n      <td>255</td>\n      <td>161</td>\n      <td>16</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>16</td>\n      <td>161</td>\n      <td>255</td>\n      <td>255</td>\n      <td>208</td>\n      <td>83</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26233</th>\n      <td>36</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26234</th>\n      <td>35</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>77</td>\n      <td>253</td>\n      <td>255</td>\n      <td>...</td>\n      <td>255</td>\n      <td>255</td>\n      <td>253</td>\n      <td>77</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26235</th>\n      <td>34</td>\n      <td>43</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>...</td>\n      <td>43</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>213</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26236</th>\n      <td>33</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>23</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>26237 rows × 401 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['font', 'fontVariant', 'strength', 'italic', 'orientation', 'm_top', 'm_left', 'originalH', 'originalW', 'h', 'w'], inplace=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, write a function that takes in one of these types of dataframe and returns 2 numpy arrays: Xs which is a #samples x 20 x 20 array containing the pixel values, and Ys which is a #samples x 1 array containing the ascii vales for each character. You should normalize the Xs array so the values go from 0-1 (most likely this requires dividing by 255)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def extract_data(df):\n",
    "    #Xs which is a #samples x 20 x 20 array containing the pixel values\n",
    "    X = df.drop(columns='m_label').to_numpy(dtype=np.float64)\n",
    "    X = np.array([x.reshape(20, 20) for x in X], dtype=np.float64) / 255\n",
    "    X = np.reshape(X, (-1, 1, 20, 20))\n",
    "\n",
    "    #Ys\n",
    "    Y_data = df[\"m_label\"].to_numpy()\n",
    "    keys, Y = np.unique(Y_data, return_inverse=True)\n",
    "    # Y = np.array(Y_data)\n",
    "\n",
    "    return X, Y , keys\n",
    "\n",
    "X, Y, keys = extract_data(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Build a PyTorch Network\n",
    "We're going to use the PyTorch library, like we've seen in class, to build/train our network. Check out the notebooks we've made in class or the official documentation/tutorials.\n",
    "\n",
    "To start with, we're going to use a model very similar to the MNIST CNN we used in class. It will consist of:\n",
    "\n",
    "* a Convolution2D layer with ReLU activations\n",
    "* a max pooling layer\n",
    "* another convolution layer\n",
    "* another max pooling layer\n",
    "* a dense layer with relu activation\n",
    "* a dense layer\n",
    "\n",
    "Compile and train your network like we did in class. You'll probably have to use the np.reshape() function on your data to make PyTorch happy. I reshaped my X values like np.reshape(Xs, (-1, 1, 20, 20)) to get them in the right format.\n",
    "\n",
    "For training, you'll want to check out torch.utils.data.DataLoader which can take a TensorDataset so you can iterate over batches like we did in class for the MNIST data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "class network1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(network1, self).__init__()\n",
    "\n",
    "        self.convolution1 = nn.Conv2d(1, 8, 3)\n",
    "        self.pooling1 = nn.MaxPool2d(2, 2)\n",
    "        self.dense1 = nn.Linear(576, 4000)\n",
    "\n",
    "        self.convolution2 = nn.Conv2d(8, 64, 3)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 2)\n",
    "        self.dense2 = nn.Linear(4000, 3098)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pooling1(F.relu(self.convolution1(x)))\n",
    "        x = self.pooling2(F.relu(self.convolution2(x)))\n",
    "\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        # Exclude Batch Dimension\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "network1 = network1().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def train( model, epochs, data, labels ):\n",
    "    print(\"Training the model, please wait...\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # use the optimiser to find weights\n",
    "    optimizer = optim.Adam( model.parameters(), lr= 1e-4 )\n",
    "\n",
    "    model.float()\n",
    "\n",
    "    for epoch in range( epochs ):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(data.float()) # Predict outputs\n",
    "        loss = criterion(outputs, labels) # Check the predictions accuracy\n",
    "\n",
    "        loss.backward() # Calculate new weights\n",
    "        optimizer.step() # Change weights and try again\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "def evaluate( model, data, labels ):\n",
    "    #load some test data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad(): # Don't calculate gradients as it's not necessary here.\n",
    "\n",
    "        outputs = model(data.float())\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print( 'Accuracy of the network: %d%%' % (100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model, please wait...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [33]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m data, labels \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# print(min(labels))\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# print(max(labels))\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnetwork1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [32]\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, epochs, data, labels)\u001B[0m\n\u001B[0;32m     17\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels) \u001B[38;5;66;03m# Check the predictions accuracy\u001B[39;00m\n\u001B[0;32m     19\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward() \u001B[38;5;66;03m# Calculate new weights\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# Change weights and try again\u001B[39;00m\n\u001B[0;32m     22\u001B[0m     running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining complete.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:109\u001B[0m, in \u001B[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    107\u001B[0m profile_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizer.step#\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.step\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(profile_name):\n\u001B[1;32m--> 109\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[1;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:113\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mno_grad()\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, closure\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;124;03m\"\"\"Performs a single optimization step.\u001B[39;00m\n\u001B[0;32m    108\u001B[0m \n\u001B[0;32m    109\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;124;03m        closure (callable, optional): A closure that reevaluates the model\u001B[39;00m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;124;03m            and returns the loss.\u001B[39;00m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 113\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cuda_graph_capture_health_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    115\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m closure \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:86\u001B[0m, in \u001B[0;36mOptimizer._cuda_graph_capture_health_check\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cuda_graph_capture_health_check\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mhas_cuda \u001B[38;5;129;01mand\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m---> 86\u001B[0m         capturing \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_current_stream_capturing\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     88\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m capturing \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m     89\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempting CUDA graph capture of step() for an instance of \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m\n\u001B[0;32m     90\u001B[0m                                \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m+\u001B[39m\n\u001B[0;32m     91\u001B[0m                                \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but this instance was constructed with capturable=False.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\graphs.py:24\u001B[0m, in \u001B[0;36mis_current_stream_capturing\u001B[1;34m()\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_current_stream_capturing\u001B[39m():\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;124;03m    Returns True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \n\u001B[0;32m     22\u001B[0m \u001B[38;5;124;03m    If a CUDA context does not exist on the current device, returns False without initializing the context.\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_cuda_isCurrentStreamCapturing\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "data = torch.from_numpy(X)\n",
    "labels = torch.from_numpy(Y)\n",
    "data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "# print(min(labels))\n",
    "# print(max(labels))\n",
    "\n",
    "\n",
    "train(network1, EPOCHS, data, labels) # Training network with an epoch value of 100, takes a long time, so set it to 1 for testing."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Evaluating the model, please wait...\")\n",
    "evaluate(network1, data, labels)\n",
    "print(\"Evaluation complete.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Exploration and Evaluation\n",
    "### Cross-validation (Training/Test Splits)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, train_size=0.5, shuffle=True)\n",
    "\n",
    "train(network1, EPOCHS, X_train, y_train)\n",
    "\n",
    "evaluate(network1, X_test, y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seems like if we train the network for 500 epochs that accuracy with cross-validation is about 83%, but in the next cell, I will increase epoch value to 1000 and then see what that does, probably increased accuracy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(network1, EPOCHS, X_train, y_train)\n",
    "\n",
    "evaluate(network1, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Turns out the accuracy increased significantly. What if I evaluate against train data?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate(network1, X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trying a different network topology"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class network2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(network2, self).__init__()\n",
    "\n",
    "        self.convolution1 = nn.Conv2d(1, 8, 2)\n",
    "        self.pooling1 = nn.MaxPool2d(2, 2)\n",
    "        self.dense1 = nn.Linear(128, 5000)\n",
    "\n",
    "        self.convolution2 = nn.Conv2d(8, 64, 2)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 2)\n",
    "        self.dense2 = nn.Linear(5000, 3098)\n",
    "\n",
    "        self.convolution3 = nn.Conv2d(64, 128, 2)\n",
    "        self.pooling3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pooling1(F.relu(self.convolution1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pooling2(F.relu(self.convolution2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pooling3(F.relu(self.convolution3(x)))\n",
    "\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        # Exclude Batch Dimension\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "network2 = network2().to(device)\n",
    "\n",
    "data = torch.from_numpy(X)\n",
    "labels = torch.from_numpy(Y)\n",
    "data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "train(network2, EPOCHS, data, labels)\n",
    "evaluate(network2, data, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looks like the new network is much worse than the first network. Also, since I am using my GPU to train the models, I will be clearing VRAM cache to make space for other computations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test accuracy of both network with other fonts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup inputs and labels for font cambria and courier."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cambria_df = pd.read_csv('fonts/CAMBRIA.csv')\n",
    "courier_df = pd.read_csv('fonts/COURIER.csv')\n",
    "\n",
    "cambria_df.drop(columns=['font', 'fontVariant', 'strength', 'italic', 'orientation', 'm_top', 'm_left', 'originalH', 'originalW', 'h', 'w'], inplace=True)\n",
    "courier_df.drop(columns=['font', 'fontVariant', 'strength', 'italic', 'orientation', 'm_top', 'm_left', 'originalH', 'originalW', 'h', 'w'], inplace=True)\n",
    "\n",
    "cambria_x, cambria_y, keys = extract_data(cambria_df)\n",
    "courier_x, courier_y, keys = extract_data(courier_df)\n",
    "\n",
    "cambria_inputs, cambria_labels = torch.from_numpy(cambria_x).to(device), torch.from_numpy(cambria_y).to(device)\n",
    "courier_inputs, courier_labels = torch.from_numpy(courier_x).to(device), torch.from_numpy(courier_y).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the networks with the other two fonts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Network 1:\")\n",
    "print(\"Cambria Font:\")\n",
    "evaluate(network1, cambria_inputs, cambria_labels)\n",
    "print(\"Courier Font:\")\n",
    "evaluate(network1, courier_inputs, courier_labels)\n",
    "print(\"\\nNetwork 2:\")\n",
    "print(\"Cambria Font:\")\n",
    "evaluate(network2, cambria_inputs, cambria_labels)\n",
    "print(\"Courier Font:\")\n",
    "evaluate(network2, courier_inputs, courier_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Both networks perform really bad."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since, network 1 is the best network, I will be training this network with cambria and courier dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(network1, EPOCHS, cambria_inputs, cambria_labels)\n",
    "train(network1, EPOCHS, courier_inputs, courier_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}